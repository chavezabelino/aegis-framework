# Aegis Framework Evaluation Suite

**First-class evals in CI** - Golden prompts, expected artifacts, and automated quality gates.

## ğŸ¯ Overview

The `/evals` directory contains:
- **Golden prompts**: Canonical test cases for blueprint generation
- **Expected artifacts**: Reference outputs for comparison
- **LLM-as-judge**: Style and quality evaluation (not correctness)
- **Delta detection**: Baseline comparison for regression testing

## ğŸ“ Structure

```
evals/
â”œâ”€â”€ golden-prompts/           # Test case definitions
â”‚   â”œâ”€â”€ feat-user-auth.yaml
â”‚   â”œâ”€â”€ feat-data-table.yaml
â”‚   â””â”€â”€ feat-public-viewing.yaml
â”œâ”€â”€ expected-artifacts/       # Reference outputs
â”‚   â”œâ”€â”€ feat-user-auth/
â”‚   â”‚   â”œâ”€â”€ output.strict.json
â”‚   â”‚   â”œâ”€â”€ generated-code/
â”‚   â”‚   â””â”€â”€ validation-results.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ baselines/               # Performance baselines
â”‚   â”œâ”€â”€ generation-speed.json
â”‚   â”œâ”€â”€ quality-scores.json
â”‚   â””â”€â”€ compliance-rates.json
â”œâ”€â”€ judges/                  # LLM evaluation prompts
â”‚   â”œâ”€â”€ code-quality.md
â”‚   â”œâ”€â”€ documentation.md
â”‚   â””â”€â”€ architectural-alignment.md
â””â”€â”€ configs/                 # Evaluation configurations
    â”œâ”€â”€ ci-config.yaml
    â”œâ”€â”€ local-config.yaml
    â””â”€â”€ enterprise-config.yaml
```

## ğŸš€ Usage

```bash
# Run full evaluation suite
aegis eval

# Run specific evaluation
aegis eval feat-user-auth

# Compare against baseline
aegis eval --baseline main

# CI mode (fail on regression)
aegis eval --ci --threshold 0.95
```

## ğŸ¬ CI Integration

Add to your `.github/workflows/aegis-eval.yml`:

```yaml
- name: Run Aegis Evaluations
  run: |
    aegis eval --ci --baseline main
    # Auto-fails if quality drops below threshold
```
