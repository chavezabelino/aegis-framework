# ğŸ›¡ï¸ Aegis Framework

> A production-grade, blueprint-driven system for AI-assisted software development â€” with full traceability, observability, drift protection, and replay fidelity.

---

## ğŸ§  What is Aegis?

**Aegis** is an AI-native engineering framework for managing complex, agent-driven software systems. It formalizes the contracts, execution rules, and validation layers required to safely scale AI-generated software â€” across tech stacks, tools, and developer contexts.

It was designed from the ground up to enforce:

- âœ… **Auditability**: Track who generated what, when, and with what context
- ğŸ” **Replayability**: Regenerate the same output from the same blueprint, deterministically
- ğŸ“ˆ **Observability**: Emit telemetry and trace blueprint coverage at runtime
- â— **Fallback Safety**: Define user-facing error states for failed AI generations
- ğŸ” **Blueprint Contracts**: Strict schemas for every AI-assisted change
- ğŸ§¬ **Rule Versioning**: Enforce specific contract versions via CI or orchestration

---

## ğŸ“‚ Project Structure

```txt
aegis-framework/
â”œâ”€â”€ framework/             # Core specs, contracts, modes, agent behaviors
â”‚   â”œâ”€â”€ framework-core-v4.6.md
â”‚   â”œâ”€â”€ contracts/         # Blueprint + rule schemas
â”‚   â”œâ”€â”€ modes/             # lean, strict, generative (token-mode configs)
â”‚   â”œâ”€â”€ agents/            # Copilot, Kilo, Lovable behavior profiles
â”‚   â””â”€â”€ versions/          # Archived framework versions
â”‚
â”œâ”€â”€ blueprints/            # Real blueprint examples (testable, replayable)
â”‚   â””â”€â”€ feat-public-viewing/
â”‚       â”œâ”€â”€ blueprint.yaml
â”‚       â”œâ”€â”€ output.lean.json
â”‚       â”œâ”€â”€ output.full.json
â”‚       â””â”€â”€ visual.png
â”‚
â”œâ”€â”€ adapters/              # Translate contracts to specific tech stacks
â”‚   â”œâ”€â”€ react-next/
â”‚   â”œâ”€â”€ deno-edge/
â”‚   â””â”€â”€ python-fastapi/
â”‚
â”œâ”€â”€ tests/                 # Snapshot & diff tests for blueprint fidelity
â”‚   â”œâ”€â”€ snapshot-tests/
â”‚   â””â”€â”€ replay-diff-tests/
â”‚
â”œâ”€â”€ tools/                 # Helpers for validation, drift detection, docgen
â”œâ”€â”€ docs/                  # Guide and architecture docs
â”‚   â”œâ”€â”€ architecture.md
â”‚   â”œâ”€â”€ guide/
â”‚   â””â”€â”€ reference/
â”‚
â”œâ”€â”€ scaffolds/             # Starter kits for framework adoption
â”‚   â””â”€â”€ web-app-starter/
â”‚
â”œâ”€â”€ cli/                   # (optional) CLI tooling
â”‚
â”œâ”€â”€ VERSION                # Current version tag
â”œâ”€â”€ CHANGELOG.md           # Semantic versioning log
â””â”€â”€ README.md              # This file
```

---

## ğŸš€ How to Use

### 1. Author a Blueprint

Create a new blueprint using `blueprints/<your-feature>/blueprint.yaml`.

Blueprints define:
- Feature intent and context
- Required routes, selectors, and components
- Associated rule contracts and error fallback UX
- Agent mode and output hash

See `framework/framework-core-v4.6.md` for the full blueprint schema.

---

### 2. Run and Compare Outputs

Execute the blueprint using your agent (Kilo, Copilot, etc.), then store:

- `output.lean.json`: minimal usage (strict match)
- `output.strict.json`: full schema coverage
- `output.full.json`: generative mode (max detail)

Use snapshot testing in `/tests/` to diff these outputs over time.

---

### 3. Validate and Observe

- Use `tools/validate-blueprint.ts` to check schema compliance.
- Use `tools/detect-drift.ts` to compare intent hash to agent outputs.
- Log observability events defined in each blueprint (`observability.events[]`).

---

### 4. Build for Any Tech Stack

Adapters in `/adapters/` allow the same blueprint to execute across:
- React + Next.js
- Deno + Edge Functions
- Python + FastAPI
- Spring Boot, Ruby, Vue, etc. (planned)

---

## ğŸ§¬ Agent Modes & Profiles

Aegis supports execution **modes** to tune agent behavior and token usage:

| Mode        | Description                          | Use Case              |
|-------------|--------------------------------------|------------------------|
| `lean`      | Minimal output, strict replay match  | Cost-sensitive ops     |
| `strict`    | Full schema compliance               | CI/QA environments     |
| `generative`| Rich creative expansion              | Ideation and design    |

Each agent (Copilot, Kilo, Lovable) has a behavior profile in `/framework/agents/`.

---

## ğŸ›£ Roadmap

- âœ… v4.6: Hardened replay, error taxonomy, observability contracts
- ğŸ”œ v4.7: Multi-agent orchestration, auto-mode selection
- ğŸ”œ v5.0: Full runtime + UI support, adapter registry

See `framework-core-v4.6.md` and `CHANGELOG.md` for full release details.

---

## ğŸ“ Resources

- [ğŸ“˜ Architecture Overview](docs/architecture.md)
- [ğŸ§© Blueprint Schema](framework/contracts/)
- [ğŸ§ª Snapshot Test Examples](tests/snapshot-tests/)
- [ğŸ›  Drift Detection Tool](tools/detect-drift.ts)
- [ğŸ§± Starter Scaffold](scaffolds/web-app-starter/)

---

## ğŸ§  Created By

This framework is part of a broader initiative to make AI-generated systems **safe**, **reliable**, and **replayable** â€” with fidelity.

It was designed to be used in production environments and across consulting, open-source, and enterprise workflows.

> _â€œWe're not building a replicator, but we are designing like someone who wants to.â€_
